# streamlit/pages/qa.py

import pandas as pd
import streamlit as st

from services.api_client import qa
from services.qdrant_service import list_collections
from state.session import require_login


def render():
    if not require_login():
        return

    st.header("ðŸ¤– Há»i Ä‘Ã¡p vá»›i AI")
    st.caption(
        "**Demo RAG:** TÃ­nh nÄƒng nÃ y dÃ¹ng Ä‘á»ƒ demo RAG (Retrieval-Augmented Generation). "
        "Há»‡ thá»‘ng (1) tÃ¬m cÃ¡c Ä‘oáº¡n tÃ i liá»‡u liÃªn quan (semantic search), (2) gá»­i lÃ m context cho AI, "
        "(3) AI **chá»‰ Ä‘Æ°á»£c tráº£ lá»i dá»±a trÃªn context Ä‘Æ°á»£c cung cáº¥p** â€” khÃ´ng dÃ¹ng kiáº¿n thá»©c bÃªn ngoÃ i. "
        "Náº¿u context khÃ´ng Ä‘á»§, AI sáº½ nÃ³i rÃµ khÃ´ng cÃ³ thÃ´ng tin. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t."
    )

    token = st.session_state.token

    # --------------------------------------------------
    # PARAMS
    # --------------------------------------------------
    try:
        collections_resp = list_collections(token)
        collections = [c["name"] for c in collections_resp] if collections_resp else ["eduai_chunks"]
    except Exception:
        collections = ["eduai_chunks"]

    col1, col2, col3, col4 = st.columns(4)

    with col1:
        collection_name = st.selectbox(
            "ðŸ“¦ Collection",
            collections,
            help="Collection Qdrant chá»©a embeddings Ä‘á»ƒ tÃ¬m context.",
        )

    with col2:
        top_k = st.slider(
            "Sá»‘ context (Top K)",
            min_value=1,
            max_value=20,
            value=5,
            help="Sá»‘ Ä‘oáº¡n tÃ i liá»‡u tá»‘i Ä‘a gá»­i lÃ m context cho LLM.",
        )

    with col3:
        temperature = st.slider(
            "Temperature",
            min_value=0.0,
            max_value=2.0,
            value=0.7,
            step=0.1,
            help="0 = chÃ­nh xÃ¡c, 2 = sÃ¡ng táº¡o hÆ¡n.",
        )

    with col4:
        use_threshold = st.checkbox("NgÆ°á»¡ng Ä‘iá»ƒm context", value=False)
        score_threshold = None
        if use_threshold:
            score_threshold = st.slider(
                "Score tá»‘i thiá»ƒu",
                min_value=0.0,
                max_value=1.0,
                value=0.5,
                step=0.05,
                key="qa_score_threshold",
            )

    question = st.text_area(
        "CÃ¢u há»i cá»§a báº¡n",
        placeholder="VÃ­ dá»¥: Quy Ä‘á»‹nh vá» kinh táº¿ quá»‘c dÃ¢n? Äiá»u kiá»‡n tuyá»ƒn sinh? ChÃ­nh sÃ¡ch há»c phÃ­?",
        height=120,
        key="qa_question",
    )

    if st.button("ðŸ” Há»i AI", type="primary"):
        if not question.strip():
            st.warning("Vui lÃ²ng nháº­p cÃ¢u há»i")
            return

        with st.spinner("Äang tÃ¬m context vÃ  gá»i LLM..."):
            try:
                data = qa(
                    question=question.strip(),
                    top_k=top_k,
                    temperature=temperature,
                    token=token,
                    collection_name=collection_name or None,
                    score_threshold=score_threshold,
                )
            except Exception as exc:
                st.error(f"Lá»—i khi gá»i API: {exc}")
                return

        # ---------- Question (echo) ----------
        st.subheader("â“ CÃ¢u há»i")
        st.write(question.strip())

        # ---------- Answer ----------
        st.subheader("ðŸ’¡ CÃ¢u tráº£ lá»i")
        answer = data.get("answer") or "KhÃ´ng cÃ³ cÃ¢u tráº£ lá»i."
        model_used = data.get("model_used")

        if model_used:
            st.caption(f"Model: **{model_used}**")

        st.markdown(answer)

        st.download_button(
            "â¬‡ï¸ Táº£i cÃ¢u tráº£ lá»i (TXT)",
            data=answer,
            file_name="qa_answer.txt",
            mime="text/plain",
            key="qa_download_answer",
        )

        # ---------- Contexts summary ----------
        contexts = data.get("contexts", [])
        st.subheader("ðŸ“š Context Ä‘Ã£ dÃ¹ng Ä‘á»ƒ tráº£ lá»i")
        st.caption(
            "CÃ¡c Ä‘oáº¡n tÃ i liá»‡u Ä‘Æ°á»£c tÃ¬m báº±ng semantic search vÃ  gá»­i cho LLM. "
            "Score = Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng vá»›i cÃ¢u há»i (0â€“1)."
        )

        if not contexts:
            st.info("KhÃ´ng cÃ³ context nÃ o Ä‘Æ°á»£c sá»­ dá»¥ng")
        else:
            scores = [c["score"] for c in contexts]
            st.metric("Sá»‘ context", len(contexts))
            st.caption(f"Score trung bÃ¬nh: {sum(scores) / len(scores):.4f} | Min: {min(scores):.4f} | Max: {max(scores):.4f}")

            # ---------- Table ----------
            st.markdown("**Báº£ng context**")
            rows = []
            for idx, ctx in enumerate(contexts, start=1):
                text = ctx.get("text") or ""
                text_preview = (text[:80] + "â€¦") if len(text) > 80 else text
                rows.append({
                    "#": idx,
                    "score": round(ctx["score"], 4),
                    "file_hash": ctx.get("file_hash"),
                    "chunk_id": ctx.get("chunk_id"),
                    "section_id": ctx.get("section_id"),
                    "text": text_preview,
                })
            df = pd.DataFrame(rows)
            st.dataframe(df, use_container_width=True)

            # ---------- Detail per context ----------
            st.markdown("**Chi tiáº¿t tá»«ng context**")
            for idx, ctx in enumerate(contexts, start=1):
                title = (
                    f"[{idx}] score = {ctx['score']:.4f} | "
                    f"file_hash = {ctx.get('file_hash') or 'â€”'} | "
                    f"chunk_id = {ctx.get('chunk_id')}"
                )
                with st.expander(title, expanded=(idx <= 2)):
                    c1, c2 = st.columns(2)
                    with c1:
                        st.write("**Metadata**")
                        st.write(f"- file_hash: `{ctx.get('file_hash') or 'â€”'}`")
                        st.write(f"- chunk_id: `{ctx.get('chunk_id')}`")
                        st.write(f"- section_id: `{ctx.get('section_id') or 'â€”'}`")
                        st.write(f"- token_estimate: `{ctx.get('token_estimate') or 'â€”'}`")
                        st.write(f"- source: `{ctx.get('source') or 'â€”'}`")
                        if ctx.get("id"):
                            st.write(f"- point id: `{ctx.get('id')}`")
                    with c2:
                        text = ctx.get("text") or "(trá»‘ng)"
                        st.write("**Ná»™i dung**")
                        st.text_area(
                            "Ná»™i dung",
                            value=text,
                            height=180,
                            key=f"qa_ctx_text_{idx}_{ctx.get('id', idx)}",
                            disabled=True,
                            label_visibility="collapsed",
                        )
                        st.download_button(
                            "â¬‡ï¸ Táº£i ná»™i dung context",
                            data=text,
                            file_name=f"context_{ctx.get('file_hash', '')}_{ctx.get('chunk_id', idx)}.txt",
                            mime="text/plain",
                            key=f"qa_ctx_dl_{idx}_{ctx.get('id', idx)}",
                        )

        # ---------- Raw response ----------
        with st.expander("ðŸ“¦ Raw API Response", expanded=False):
            st.json(data)

    else:
        st.info("Nháº­p cÃ¢u há»i vÃ  báº¥m **Há»i AI** Ä‘á»ƒ báº¯t Ä‘áº§u.")
