# frontend/streamlit/pages/data_lake_explorer.py

from pathlib import Path
import hashlib
import json
import os
import sqlite3

import pandas as pd
import streamlit as st

from config.settings import DATA_ROOT
from state.session import require_login
from services.api_client import get_data_path_from_api

# File viewer: giá»›i háº¡n kÃ­ch thÆ°á»›c (trÃ¡nh treo)
MAX_VIEW_TEXT_BYTES = 10 * 1024 * 1024   # 10 MB cho txt/json/jsonl
MAX_VIEW_NPY_BYTES = 5 * 1024 * 1024     # 5 MB cho npy
MAX_VIEW_PDF_BYTES = 50 * 1024 * 1024    # 50 MB cho pdf
MAX_JSONL_LINES = 500

# =====================================================
# DATA ZONES
# =====================================================

ZONE_NAMES = [
    "000_inbox",
    "100_raw",
    "200_staging",
    "300_processed",
    "400_embeddings",
    "500_catalog",
]

def _zones_from_root(root: Path) -> dict[str, Path]:
    return {z: root / z for z in ZONE_NAMES}

# Fallback khi chÆ°a gá»i API (module load)
ZONES = _zones_from_root(DATA_ROOT)

MAX_TREE_DEPTH = 30  # Giá»›i háº¡n Ä‘á»™ sÃ¢u trÃ¡nh Ä‘á»‡ quy vÃ´ háº¡n
CACHE_TTL_TREE = 90  # GiÃ¢y cache cho list_dir (NAS cháº­m)

# BÆ°á»›c pipeline: 0=inboxâ†’raw, 1=rawâ†’staging, 2=stagingâ†’processed, 3=processedâ†’embeddings, 4=embeddingsâ†’Qdrant
PIPELINE_STEP_LABELS = {
    0: "Step 0 (Inbox â†’ Raw)",
    1: "Step 1 (Raw â†’ Staging)",
    2: "Step 2 (Staging â†’ Processed)",
    3: "Step 3 (Processed â†’ Embeddings)",
    4: "Step 4 (Embeddings â†’ Qdrant)",
}

# Cá»™t tráº¡ng thÃ¡i tá»«ng bÆ°á»›c cho file trong 000_inbox
INBOX_STEP_COLUMNS = ["Ingest", "Staging", "Processed", "Embeddings", "Qdrant"]


# =====================================================
# CACHE Äá»ŒC NAS (giáº£m lag, trÃ¡nh Ä‘á»c láº¡i cÃ¹ng path)
# =====================================================

@st.cache_data(ttl=CACHE_TTL_TREE)
def _list_dir_cached(path_str: str) -> tuple[list[str], list[tuple[str, int]]]:
    """
    Äá»c thÆ° má»¥c tá»« NAS, tráº£ vá» (tÃªn thÆ° má»¥c, [(tÃªn file, size)]).
    DÃ¹ng thread Ä‘á»ƒ khÃ´ng block UI; káº¿t quáº£ Ä‘Æ°á»£c cache.
    """
    path = Path(path_str)
    dirs, files = [], []
    try:
        for p in sorted(path.iterdir()):
            if p.name.startswith("."):
                continue
            if p.is_dir():
                dirs.append(p.name)
            elif p.is_file():
                try:
                    files.append((p.name, p.stat().st_size))
                except OSError:
                    files.append((p.name, 0))
    except (PermissionError, OSError):
        pass
    return (sorted(dirs, key=str.lower), sorted(files, key=lambda x: x[0].lower()))


# =====================================================
# TREE VIEW â€” LAZY LOADING
# =====================================================

def _format_size(size_bytes: int) -> str:
    if size_bytes < 1024:
        return f"{size_bytes} B"
    if size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    return f"{size_bytes / (1024 * 1024):.1f} MB"


def _path_to_key(path_str: str) -> str:
    """Táº¡o key widget duy nháº¥t tá»« path (trÃ¡nh trÃ¹ng khi path dÃ i)."""
    return hashlib.md5(path_str.encode()).hexdigest()[:24]


@st.cache_data(ttl=120)
def _sha256_file_cached(path_str: str) -> str | None:
    """TÃ­nh SHA256 cá»§a file (Ä‘á»ƒ Ä‘á»‘i chiáº¿u vá»›i raw_objects). Cache 120s."""
    path = Path(path_str)
    if not path.is_file():
        return None
    try:
        h = hashlib.sha256()
        with path.open("rb") as f:
            while chunk := f.read(1024 * 1024):
                h.update(chunk)
        return h.hexdigest()
    except (OSError, PermissionError):
        return None


def get_inbox_file_pipeline_steps(file_path: Path, domain: str) -> dict[str, str]:
    """
    Vá»›i file trong 000_inbox: tráº£ vá» tá»«ng bÆ°á»›c Ä‘Ã£ xá»­ lÃ½ hay chÆ°a.
    Keys: Ingest, Staging, Processed, Embeddings, Qdrant. Value: "âœ“" hoáº·c "" (Qdrant cÃ³ thá»ƒ "?" náº¿u khÃ´ng biáº¿t).
    """
    result = {k: "" for k in INBOX_STEP_COLUMNS}
    path_str = str(file_path.resolve())
    file_hash = _sha256_file_cached(path_str)
    if not file_hash:
        return result
    root = DATA_ROOT
    catalog_db = root / "500_catalog" / "catalog.sqlite"
    # Step 0: Ingest (Ä‘Ã£ cÃ³ trong raw_objects)
    try:
        if catalog_db.exists():
            conn = sqlite3.connect(f"file:{catalog_db}?mode=ro", uri=True, timeout=5)
            cur = conn.execute("SELECT 1 FROM raw_objects WHERE hash = ? LIMIT 1", (file_hash,))
            if cur.fetchone():
                result["Ingest"] = "âœ“"
            conn.close()
    except Exception:
        pass
    if result["Ingest"] != "âœ“":
        return result
    # Steps 1â€“3: kiá»ƒm tra thÆ° má»¥c; há»— trá»£ cáº£ domain/hash vÃ  hash (cáº¥u trÃºc cÅ©)
    _staging_dir = root / "200_staging" / domain / file_hash if domain and domain != "." else root / "200_staging" / file_hash
    _staging_alt = root / "200_staging" / file_hash if domain and domain != "." else None
    if (_staging_dir / "validation.json").exists() or (_staging_alt and (_staging_alt / "validation.json").exists()):
        result["Staging"] = "âœ“"
    _processed_dir = root / "300_processed" / domain / file_hash if domain and domain != "." else root / "300_processed" / file_hash
    _processed_alt = root / "300_processed" / file_hash if domain and domain != "." else None
    if (_processed_dir / "chunks.json").exists() or (_processed_alt and (_processed_alt / "chunks.json").exists()):
        result["Processed"] = "âœ“"
    _emb_dir = root / "400_embeddings" / domain / file_hash if domain and domain != "." else root / "400_embeddings" / file_hash
    _emb_alt = root / "400_embeddings" / file_hash if domain and domain != "." else None
    if (_emb_dir / "embedding.npy").exists() or (_emb_alt and (_emb_alt / "embedding.npy").exists()):
        result["Embeddings"] = "âœ“"
    # Step 4: Qdrant â€” khÃ´ng cÃ³ trong catalog, Ä‘á»ƒ trá»‘ng hoáº·c "?"
    result["Qdrant"] = "?" if result["Embeddings"] == "âœ“" else ""
    return result


def get_raw_file_pipeline_steps(file_path: Path, domain: str) -> dict[str, str]:
    """
    Vá»›i file trong 100_raw: Ingest luÃ´n âœ“ (Ä‘Ã£ á»Ÿ Raw), cÃ¡c bÆ°á»›c sau kiá»ƒm tra theo domain/hash.
    file_hash = file_path.stem (tÃªn file khÃ´ng extension).
    """
    result = {k: "" for k in INBOX_STEP_COLUMNS}
    result["Ingest"] = "âœ“"  # ÄÃ£ ingest (file Ä‘ang á»Ÿ Raw)
    file_hash = file_path.stem
    domain = domain or "."
    root = DATA_ROOT
    # Há»— trá»£ cáº£ domain/hash vÃ  hash (cáº¥u trÃºc cÅ©); backend ghi embedding.npy (khÃ´ng cÃ³ s)
    _staging = root / "200_staging" / domain / file_hash if domain != "." else root / "200_staging" / file_hash
    _staging_alt = root / "200_staging" / file_hash if domain != "." else None
    if (_staging / "validation.json").exists() or (_staging_alt and (_staging_alt / "validation.json").exists()):
        result["Staging"] = "âœ“"
    _processed = root / "300_processed" / domain / file_hash if domain != "." else root / "300_processed" / file_hash
    _processed_alt = root / "300_processed" / file_hash if domain != "." else None
    if (_processed / "chunks.json").exists() or (_processed_alt and (_processed_alt / "chunks.json").exists()):
        result["Processed"] = "âœ“"
    _emb = root / "400_embeddings" / domain / file_hash if domain != "." else root / "400_embeddings" / file_hash
    _emb_alt = root / "400_embeddings" / file_hash if domain != "." else None
    if (_emb / "embedding.npy").exists() or (_emb_alt and (_emb_alt / "embedding.npy").exists()):
        result["Embeddings"] = "âœ“"
    result["Qdrant"] = "?" if result["Embeddings"] == "âœ“" else ""
    return result


def render_folder_tree(
    root: Path,
    zone_name: str,
    expanded_set: set[str],
    current_folder: str | None,
    zone_root: Path,
    depth: int = 0,
) -> None:
    """
    Chá»‰ hiá»ƒn thá»‹ cÃ¢y thÆ° má»¥c (khÃ´ng cÃ³ file). Báº¥m thÆ° má»¥c = má»Ÿ/Ä‘Ã³ng + chá»n Ä‘á»ƒ hiá»ƒn thá»‹ danh sÃ¡ch file bÃªn pháº£i.
    """
    if depth >= MAX_TREE_DEPTH:
        st.caption("â€¦ (Ä‘áº¡t giá»›i háº¡n Ä‘á»™ sÃ¢u)")
        return

    path_str = str(root.resolve())
    try:
        dir_names, _ = _list_dir_cached(path_str)
    except Exception as e:
        st.caption(f"âš ï¸ Lá»—i: {e}")
        return

    indent = "  " * depth  # 2 space cho gá»n

    for d_name in dir_names:
        child_path = root / d_name
        child_str = str(child_path.resolve())
        key_suffix = _path_to_key(child_str)
        is_selected = current_folder == child_str
        icon = "â–¼" if child_str in expanded_set else "â–¶"
        try:
            child_dirs, child_files = _list_dir_cached(child_str)
            count = len(child_dirs) + len(child_files)
            count_str = f" ({count})"
        except Exception:
            count_str = ""
        label = f"{indent}{icon} {d_name}{count_str}" + (" âœ“" if is_selected else "")

        if st.button(label, key=f"tree_{zone_name}_{key_suffix}", type="primary" if is_selected else "secondary"):
            if child_str in expanded_set:
                expanded_set.discard(child_str)
            else:
                expanded_set.add(child_str)
            st.session_state["datalake_current_folder"] = child_str
            st.rerun()

        if child_str in expanded_set:
            render_folder_tree(child_path, zone_name, expanded_set, current_folder, zone_root, depth + 1)


def render_file_list(
    folder_path: Path,
    zone_name: str,
    zone_root: Path,
    selected_file: str | None,
) -> None:
    """
    Hiá»ƒn thá»‹ danh sÃ¡ch file trong thÆ° má»¥c dáº¡ng báº£ng; chá»n dÃ²ng Ä‘á»ƒ xem ná»™i dung.
    """
    if not _is_safe_path(folder_path, zone_root):
        st.warning("ThÆ° má»¥c khÃ´ng thuá»™c zone.")
        return
    try:
        _, file_infos = _list_dir_cached(str(folder_path.resolve()))
    except Exception as e:
        st.warning(f"KhÃ´ng Ä‘á»c Ä‘Æ°á»£c thÆ° má»¥c: {e}")
        return

    if not file_infos:
        st.info("ThÆ° má»¥c trá»‘ng hoáº·c khÃ´ng cÃ³ file.")
        return

    # 000_inbox hoáº·c 100_raw (Gá»‘c hoáº·c thÆ° má»¥c domain): báº£ng cÃ³ cá»™t tá»«ng bÆ°á»›c vá»›i âœ“
    # 100_raw bá» qua bÆ°á»›c Ingest (luÃ´n âœ“ vÃ¬ file Ä‘Ã£ á»Ÿ Raw)
    # Zone khÃ¡c: báº£ng cÃ³ cá»™t BÆ°á»›c pipeline (mÃ´ táº£ text)
    rows = []
    is_inbox_zone = zone_name == "000_inbox"
    is_raw_zone = zone_name == "100_raw"
    use_step_columns = is_inbox_zone or is_raw_zone
    # Domain = segment Ä‘áº§u tiÃªn dÆ°á»›i zone (Ä‘á»ƒ Ä‘Ãºng cáº£ khi xem file trong thÆ° má»¥c con, vd. 000_inbox/education/2024/)
    try:
        rel = folder_path.resolve().relative_to(zone_root.resolve())
        domain = rel.parts[0] if rel.parts else "."
    except (ValueError, OSError):
        domain = "." if folder_path.resolve() == zone_root.resolve() else folder_path.name
    for f_name, size in file_infos:
        file_path = folder_path / f_name
        _path = str(file_path.resolve())
        if use_step_columns and is_inbox_zone:
            steps = get_inbox_file_pipeline_steps(file_path, domain)
            rows.append({
                "TÃªn file": f_name,
                "KÃ­ch thÆ°á»›c": _format_size(size),
                **{col: steps.get(col, "") for col in INBOX_STEP_COLUMNS},
                "_path": _path,
            })
        elif use_step_columns and is_raw_zone:
            steps = get_raw_file_pipeline_steps(file_path, domain)
            rows.append({
                "TÃªn file": f_name,
                "KÃ­ch thÆ°á»›c": _format_size(size),
                **{col: steps.get(col, "") for col in INBOX_STEP_COLUMNS},
                "_path": _path,
            })
        else:
            step_label = get_pipeline_step_for_path(
                file_path, zone_name, data_root=zone_root.parent
            )
            step_str = step_label if step_label else "â€”"
            rows.append({
                "TÃªn file": f_name,
                "KÃ­ch thÆ°á»›c": _format_size(size),
                "BÆ°á»›c pipeline": step_str,
                "_path": _path,
            })

    if use_step_columns:
        df = pd.DataFrame([{k: r[k] for k in ["TÃªn file", "KÃ­ch thÆ°á»›c"] + INBOX_STEP_COLUMNS} for r in rows])
        if is_inbox_zone:
            st.caption("âœ“ = Ä‘Ã£ xá»­ lÃ½ bÆ°á»›c Ä‘Ã³. Ingest = Step 0 (â†’ Raw), Staging = Step 1, Processed = Step 2, Embeddings = Step 3, Qdrant = Step 4 (?) náº¿u chÆ°a xÃ¡c nháº­n.")
        else:
            st.caption("âœ“ = Ä‘Ã£ xá»­ lÃ½ bÆ°á»›c Ä‘Ã³. File trong Raw nÃªn Ingest luÃ´n âœ“. Staging = Step 1, Processed = Step 2, Embeddings = Step 3, Qdrant = Step 4 (?) náº¿u chÆ°a xÃ¡c nháº­n.")
    else:
        df = pd.DataFrame([{"TÃªn file": r["TÃªn file"], "KÃ­ch thÆ°á»›c": r["KÃ­ch thÆ°á»›c"], "BÆ°á»›c pipeline": r["BÆ°á»›c pipeline"]} for r in rows])

    st.markdown(f"**Files trong** `{folder_path.name}`")
    st.dataframe(df, use_container_width=True, hide_index=True)

    chosen = st.selectbox(
        "Chá»n file Ä‘á»ƒ xem ná»™i dung",
        options=[r["_path"] for r in rows],
        format_func=lambda p: Path(p).name,
        index=next((i for i, r in enumerate(rows) if r["_path"] == selected_file), 0),
        key=f"file_sel_{zone_name}_{_path_to_key(str(folder_path.resolve()))}",
    )
    if chosen:
        st.session_state["datalake_selected_file"] = chosen


def get_pipeline_step_for_path(
    file_path: Path, zone_name: str, data_root: Path | None = None
) -> str | None:
    """
    XÃ¡c Ä‘á»‹nh file Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ tá»›i bÆ°á»›c nÃ o trong pipeline (0â€“4) báº±ng catalog vÃ  kiá»ƒm tra file há»‡ thá»‘ng.
    Tráº£ vá» mÃ´ táº£ bÆ°á»›c hoáº·c None náº¿u khÃ´ng xÃ¡c Ä‘á»‹nh Ä‘Æ°á»£c.
    data_root: náº¿u cÃ³ thÃ¬ dÃ¹ng (path tá»« backend); khÃ´ng thÃ¬ dÃ¹ng DATA_ROOT tá»« env.
    """
    root = data_root if data_root is not None else DATA_ROOT
    staging_root = root / "200_staging"
    processed_root = root / "300_processed"
    embeddings_root = root / "400_embeddings"
    catalog_db = root / "500_catalog" / "catalog.sqlite"

    if zone_name == "000_inbox":
        return "ChÆ°a cháº¡y Step 0 (file váº«n trong Inbox)"
    if zone_name not in ("100_raw", "200_staging", "300_processed", "400_embeddings"):
        return None

    file_hash = None
    domain = None
    zone_root = root / zone_name if data_root is not None else ZONES.get(zone_name)
    if not zone_root:
        return None
    try:
        rel = file_path.resolve().relative_to(zone_root.resolve())
        parts = rel.parts
        if zone_name == "100_raw" and file_path.is_file():
            file_hash = file_path.stem
            domain = parts[0] if len(parts) >= 2 else None
        elif zone_name in ("200_staging", "300_processed", "400_embeddings"):
            if file_path.is_dir():
                file_hash = file_path.name
                domain = parts[0] if len(parts) >= 2 else None
            else:
                file_hash = file_path.parent.name
                domain = parts[0] if len(parts) >= 2 else None
    except ValueError:
        return None
    if not file_hash:
        return None

    domain = domain or "."
    step = -1
    if not catalog_db.exists():
        return "Catalog chÆ°a cÃ³ (chÆ°a cháº¡y Step 0)"

    try:
        conn = sqlite3.connect(f"file:{catalog_db}?mode=ro", uri=True, timeout=5)
        cur = conn.execute("SELECT 1 FROM raw_objects WHERE hash = ? LIMIT 1", (file_hash,))
        if cur.fetchone():
            step = 0
        conn.close()
    except Exception:
        return "KhÃ´ng Ä‘á»c Ä‘Æ°á»£c Catalog"

    if step < 0:
        return "ChÆ°a cÃ³ trong Catalog (chÆ°a cháº¡y Step 0)"

    domain = domain or "."
    # Há»— trá»£ cáº£ domain/hash vÃ  hash (cáº¥u trÃºc cÅ©); backend ghi embedding.npy (khÃ´ng cÃ³ s)
    _staging = staging_root / domain / file_hash if domain != "." else staging_root / file_hash
    _staging_alt = staging_root / file_hash if domain != "." else None
    if (_staging / "validation.json").exists() or (_staging_alt and (_staging_alt / "validation.json").exists()):
        step = 1
    _processed = processed_root / domain / file_hash if domain != "." else processed_root / file_hash
    _processed_alt = processed_root / file_hash if domain != "." else None
    if (_processed / "chunks.json").exists() or (_processed_alt and (_processed_alt / "chunks.json").exists()):
        step = 2
    _emb = embeddings_root / domain / file_hash if domain != "." else embeddings_root / file_hash
    _emb_alt = embeddings_root / file_hash if domain != "." else None
    if (_emb / "embedding.npy").exists() or (_emb_alt and (_emb_alt / "embedding.npy").exists()):
        step = 3
    # Step 4: cáº§n query Qdrant Ä‘á»ƒ xÃ¡c nháº­n â€” hiá»‡n khÃ´ng cÃ³ trong catalog

    return PIPELINE_STEP_LABELS.get(step, f"Step {step}")


def _is_safe_path(file_path: Path, zone_root: Path) -> bool:
    """Äáº£m báº£o file náº±m trong zone (trÃ¡nh path traversal)."""
    try:
        return file_path.resolve().is_relative_to(zone_root.resolve())
    except (ValueError, OSError):
        return False


def render_file_content(file_path: Path) -> None:
    """
    Hiá»ƒn thá»‹ ná»™i dung file theo Ä‘á»‹nh dáº¡ng: txt, json, jsonl, npy, pdf, csv.
    Giá»›i háº¡n kÃ­ch thÆ°á»›c Ä‘á»ƒ trÃ¡nh treo.
    """
    if not file_path.is_file():
        st.warning("File khÃ´ng tá»“n táº¡i hoáº·c khÃ´ng Ä‘á»c Ä‘Æ°á»£c.")
        return

    try:
        size = file_path.stat().st_size
    except OSError:
        st.error("KhÃ´ng Ä‘á»c Ä‘Æ°á»£c thÃ´ng tin file.")
        return

    suffix = file_path.suffix.lower()

    # ---------- TXT ----------
    if suffix == ".txt":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File quÃ¡ lá»›n ({size / (1024*1024):.1f} MB). Chá»‰ há»— trá»£ xem file â‰¤ {MAX_VIEW_TEXT_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            text = file_path.read_text(encoding="utf-8", errors="replace")
            st.code(text, language="text")
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c file: {e}")

    # ---------- JSON ----------
    elif suffix == ".json":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File quÃ¡ lá»›n. Chá»‰ há»— trá»£ xem file â‰¤ {MAX_VIEW_TEXT_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            with file_path.open("r", encoding="utf-8") as f:
                data = json.load(f)
            st.json(data)
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c JSON: {e}")

    # ---------- JSONL ----------
    elif suffix == ".jsonl":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File quÃ¡ lá»›n. Chá»‰ hiá»ƒn thá»‹ tá»‘i Ä‘a {MAX_JSONL_LINES} dÃ²ng Ä‘áº§u.")
        try:
            lines = []
            with file_path.open("r", encoding="utf-8", errors="replace") as f:
                for i, line in enumerate(f):
                    if i >= MAX_JSONL_LINES:
                        st.caption(f"â€¦ Chá»‰ hiá»ƒn thá»‹ {MAX_JSONL_LINES} dÃ²ng Ä‘áº§u. Tá»•ng file cÃ³ thá»ƒ nhiá»u hÆ¡n.")
                        break
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        lines.append(json.loads(line))
                    except json.JSONDecodeError:
                        lines.append({"raw": line})
            if lines:
                st.dataframe(lines, use_container_width=True)
            else:
                st.info("File rá»—ng hoáº·c khÃ´ng cÃ³ dÃ²ng JSON há»£p lá»‡.")
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c file: {e}")

    # ---------- NPY ----------
    elif suffix == ".npy":
        if size > MAX_VIEW_NPY_BYTES:
            st.warning(f"File quÃ¡ lá»›n ({size / (1024*1024):.1f} MB). Chá»‰ há»— trá»£ xem file â‰¤ {MAX_VIEW_NPY_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            import numpy as np
            arr = np.load(file_path, allow_pickle=False)
            st.write("**Shape:**", arr.shape)
            st.write("**Dtype:**", str(arr.dtype))
            if arr.size <= 100:
                st.write("**Dá»¯ liá»‡u:**")
                st.write(arr)
            else:
                st.write("**Máº«u (100 pháº§n tá»­ Ä‘áº§u):**")
                st.write(arr.flat[:100])
        except ImportError:
            st.info("Cáº§n cÃ i `numpy` Ä‘á»ƒ xem file .npy. Báº¡n cÃ³ thá»ƒ táº£i file xuá»‘ng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c file .npy: {e}")

    # ---------- PDF ----------
    elif suffix == ".pdf":
        if size > MAX_VIEW_PDF_BYTES:
            st.warning(f"File quÃ¡ lá»›n. Chá»‰ há»— trá»£ thÃ´ng tin file â‰¤ {MAX_VIEW_PDF_BYTES // (1024*1024)} MB.")
        try:
            from pypdf import PdfReader
            reader = PdfReader(file_path)
            n_pages = len(reader.pages)
            st.write(f"**Sá»‘ trang:** {n_pages}")
            _download_button(file_path)
        except ImportError:
            st.info("Cáº§n cÃ i `pypdf` Ä‘á»ƒ xem thÃ´ng tin PDF. Báº¡n cÃ³ thá»ƒ táº£i file xuá»‘ng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c PDF: {e}")
            _download_button(file_path)

    # ---------- CSV ----------
    elif suffix == ".csv":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File quÃ¡ lá»›n. Chá»‰ hiá»ƒn thá»‹ má»™t pháº§n.")
        try:
            import pandas as pd
            df = pd.read_csv(file_path, nrows=1000, encoding="utf-8", on_bad_lines="skip")
            st.dataframe(df, use_container_width=True)
            if size > 1024 * 1024:
                st.caption("Chá»‰ hiá»ƒn thá»‹ 1000 dÃ²ng Ä‘áº§u.")
        except ImportError:
            st.info("Cáº§n cÃ i `pandas` Ä‘á»ƒ xem CSV. Báº¡n cÃ³ thá»ƒ táº£i file xuá»‘ng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c CSV: {e}")

    # ---------- KhÃ¡c ----------
    else:
        st.info(f"Äá»‹nh dáº¡ng `{suffix}` chÆ°a há»— trá»£ xem trá»±c tiáº¿p. Báº¡n cÃ³ thá»ƒ táº£i file xuá»‘ng.")
        _download_button(file_path)


def _download_button(file_path: Path) -> None:
    try:
        data = file_path.read_bytes()
        st.download_button(
            "â¬‡ï¸ Táº£i file xuá»‘ng",
            data=data,
            file_name=file_path.name,
            mime="application/octet-stream",
            key=f"dl_{hashlib.md5(str(file_path).encode()).hexdigest()[:16]}",
        )
    except Exception:
        pass


# =====================================================
# MAIN PAGE
# =====================================================

def render():
    if not require_login():
        return

    # Láº¥y data root tá»« backend (Ä‘Ãºng path khi cháº¡y dev; trÃ¡nh /data máº·c Ä‘á»‹nh)
    if "data_lake_root" not in st.session_state:
        api_path = get_data_path_from_api()
        if api_path:
            st.session_state["data_lake_root"] = Path(api_path).expanduser().resolve()
        else:
            st.session_state["data_lake_root"] = DATA_ROOT
    effective_root = st.session_state["data_lake_root"]
    zones = _zones_from_root(effective_root)

    st.header("ğŸ—‚ï¸ Data Lake Explorer")
    st.caption(
        "Xem cáº¥u trÃºc Data Lake. Khi báº¥m vÃ o file, hiá»ƒn thá»‹ ná»™i dung vÃ  **bÆ°á»›c pipeline** (tá»« Catalog: Ä‘Ã£ cháº¡y Step 0â€“3). "
        "Catalog (500_catalog) chá»©a raw_objects, ingest_log."
    )

    # --------------------------------------------------
    # SELECT ZONE
    # --------------------------------------------------
    zone_name = st.selectbox(
        "ğŸ“‚ Chá»n data zone",
        list(zones.keys()),
    )

    zone_path = zones[zone_name]

    if not zone_path.exists():
        st.warning(f"Zone chÆ°a tá»“n táº¡i: {zone_path}")
        return

    st.subheader(f"ğŸ“ {zone_name}")

    if "datalake_expanded" not in st.session_state:
        st.session_state.datalake_expanded = {}
    expanded_set = st.session_state.datalake_expanded.setdefault(zone_name, set())
    zone_root_str = str(zone_path.resolve())
    current_folder = st.session_state.get("datalake_current_folder")
    if not current_folder:
        current_folder = zone_root_str
    else:
        try:
            Path(current_folder).resolve().relative_to(zone_path.resolve())
        except (ValueError, OSError, TypeError):
            current_folder = zone_root_str
    if not current_folder:
        current_folder = zone_root_str

    # --------------------------------------------------
    # LAYOUT 2 Cá»˜T: CÃ¢y thÆ° má»¥c (gá»n) trÃ¡i | Báº£ng file + ná»™i dung pháº£i
    # --------------------------------------------------
    col_tree, col_files = st.columns([0.9, 2.1])

    with col_tree:
        st.markdown("**ğŸ“ ThÆ° má»¥c**")
        try:
            root_dirs, root_files = _list_dir_cached(zone_root_str)
            root_count = len(root_dirs) + len(root_files)
            root_label = f"ğŸ“‚ Gá»‘c ({root_count})"
        except Exception:
            root_label = "ğŸ“‚ Gá»‘c"
        if st.button(root_label, key="datalake_root", help="Xem file trong thÆ° má»¥c gá»‘c zone"):
            st.session_state["datalake_current_folder"] = zone_root_str
            st.rerun()
        st.divider()
        with st.spinner("Äang táº£i cÃ¢y..."):
            render_folder_tree(zone_path, zone_name, expanded_set, current_folder, zone_path)

    with col_files:
        st.markdown("**ğŸ“„ Danh sÃ¡ch file**")
        folder_path = Path(current_folder)

        with st.spinner("Äang táº£i danh sÃ¡ch..."):
            render_file_list(folder_path, zone_name, zone_path, st.session_state.get("datalake_selected_file"))

        # Ná»™i dung file khi Ä‘Ã£ chá»n
        selected = st.session_state.get("datalake_selected_file")
        if selected:
            sel_path = Path(selected)
            if sel_path.is_file() and _is_safe_path(sel_path, zone_path):
                st.divider()
                st.subheader(f"ğŸ“„ `{sel_path.name}`")
                step_info = get_pipeline_step_for_path(
                    sel_path, zone_name, data_root=effective_root
                )
                if step_info:
                    st.caption(f"ğŸ”„ **Pipeline:** {step_info}")
                if st.button("âœ• ÄÃ³ng xem file", key="datalake_close_file"):
                    del st.session_state["datalake_selected_file"]
                    st.rerun()
                render_file_content(sel_path)

    if zone_name == "500_catalog":
        st.caption("Xem ná»™i dung SQLite (catalog) táº¡i **ğŸ—„ï¸ SQLite Viewer** trÃªn thanh bÃªn trÃ¡i.")
