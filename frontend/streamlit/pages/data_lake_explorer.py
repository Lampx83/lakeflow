# frontend/streamlit/pages/data_lake_explorer.py

from pathlib import Path
import hashlib
import json

import streamlit as st

from config.settings import DATA_ROOT
from state.session import require_login
from utils.sqlite_viewer import (
    connect_readonly,
    list_tables,
    get_table_schema,
    preview_table,
)

# File viewer: gi·ªõi h·∫°n k√≠ch th∆∞·ªõc (tr√°nh treo)
MAX_VIEW_TEXT_BYTES = 10 * 1024 * 1024   # 10 MB cho txt/json/jsonl
MAX_VIEW_NPY_BYTES = 5 * 1024 * 1024     # 5 MB cho npy
MAX_VIEW_PDF_BYTES = 50 * 1024 * 1024    # 50 MB cho pdf
MAX_JSONL_LINES = 500

# =====================================================
# DATA ZONES
# =====================================================

ZONES = {
    "000_inbox": DATA_ROOT / "000_inbox",
    "100_raw": DATA_ROOT / "100_raw",
    "200_staging": DATA_ROOT / "200_staging",
    "300_processed": DATA_ROOT / "300_processed",
    "400_embeddings": DATA_ROOT / "400_embeddings",
    "500_catalog": DATA_ROOT / "500_catalog",
}

MAX_TREE_DEPTH = 30  # Gi·ªõi h·∫°n ƒë·ªô s√¢u tr√°nh ƒë·ªá quy v√¥ h·∫°n
CACHE_TTL_TREE = 90  # Gi√¢y cache cho list_dir (NAS ch·∫≠m)


# =====================================================
# CACHE ƒê·ªåC NAS (gi·∫£m lag, tr√°nh ƒë·ªçc l·∫°i c√πng path)
# =====================================================

@st.cache_data(ttl=CACHE_TTL_TREE)
def _list_dir_cached(path_str: str) -> tuple[list[str], list[tuple[str, int]]]:
    """
    ƒê·ªçc th∆∞ m·ª•c t·ª´ NAS, tr·∫£ v·ªÅ (t√™n th∆∞ m·ª•c, [(t√™n file, size)]).
    D√πng thread ƒë·ªÉ kh√¥ng block UI; k·∫øt qu·∫£ ƒë∆∞·ª£c cache.
    """
    path = Path(path_str)
    dirs, files = [], []
    try:
        for p in sorted(path.iterdir()):
            if p.name.startswith("."):
                continue
            if p.is_dir():
                dirs.append(p.name)
            elif p.is_file():
                try:
                    files.append((p.name, p.stat().st_size))
                except OSError:
                    files.append((p.name, 0))
    except (PermissionError, OSError):
        pass
    return (sorted(dirs, key=str.lower), sorted(files, key=lambda x: x[0].lower()))


# =====================================================
# TREE VIEW ‚Äî LAZY LOADING
# =====================================================

def _format_size(size_bytes: int) -> str:
    if size_bytes < 1024:
        return f"{size_bytes} B"
    if size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    return f"{size_bytes / (1024 * 1024):.1f} MB"


def _path_to_key(path_str: str) -> str:
    """T·∫°o key widget duy nh·∫•t t·ª´ path (tr√°nh tr√πng khi path d√†i)."""
    return hashlib.md5(path_str.encode()).hexdigest()[:24]


def render_lazy_tree(
    root: Path,
    zone_name: str,
    expanded_set: set[str],
    depth: int = 0,
) -> None:
    """
    Lazy loading: ch·ªâ g·ªçi _list_dir_cached cho root v√† c√°c path ƒë√£ ƒë∆∞·ª£c user b·∫•m m·ªü (trong expanded_set).
    Khi v√†o trang ch·ªâ load root. B·∫•m ‚ñ∂ m·ªõi load th∆∞ m·ª•c con.
    """
    if depth >= MAX_TREE_DEPTH:
        st.caption("‚Ä¶ (ƒë·∫°t gi·ªõi h·∫°n ƒë·ªô s√¢u)")
        return

    path_str = str(root.resolve())
    try:
        dir_names, file_infos = _list_dir_cached(path_str)
    except Exception as e:
        st.caption(f"‚ö†Ô∏è L·ªói: {e}")
        return

    indent = "„ÄÄ" * depth  # full-width space cho th·ª•t d√≤ng

    # Th∆∞ m·ª•c con tr∆∞·ªõc: ‚ñ∂ = ch∆∞a m·ªü (b·∫•m ƒë·ªÉ load), ‚ñº = ƒë√£ m·ªü (b·∫•m ƒë·ªÉ ƒë√≥ng)
    for d_name in dir_names:
        child_path = root / d_name
        child_str = str(child_path.resolve())
        key_suffix = _path_to_key(child_str)

        if child_str not in expanded_set:
            if st.button(f"{indent}‚ñ∂ üìÅ **{d_name}**", key=f"expand_{zone_name}_{key_suffix}"):
                expanded_set.add(child_str)
                st.rerun()
        else:
            if st.button(f"{indent}‚ñº üìÅ **{d_name}**", key=f"collapse_{zone_name}_{key_suffix}"):
                expanded_set.discard(child_str)
                st.rerun()
            # ƒê√£ m·ªü ‚Üí load v√† hi·ªÉn th·ªã n·ªôi dung b√™n trong
            render_lazy_tree(child_path, zone_name, expanded_set, depth + 1)

    # File trong th∆∞ m·ª•c hi·ªán t·∫°i: b·∫•m ƒë·ªÉ xem n·ªôi dung
    for f_name, size in file_infos:
        file_path = root / f_name
        file_key = _path_to_key(str(file_path.resolve()))
        if st.button(
            f"{indent}üìÑ **{f_name}** ‚Äî {_format_size(size)}",
            key=f"file_{zone_name}_{file_key}",
            help="B·∫•m ƒë·ªÉ xem n·ªôi dung file",
        ):
            st.session_state["datalake_selected_file"] = str(file_path.resolve())
            st.rerun()


def _is_safe_path(file_path: Path, zone_root: Path) -> bool:
    """ƒê·∫£m b·∫£o file n·∫±m trong zone (tr√°nh path traversal)."""
    try:
        return file_path.resolve().is_relative_to(zone_root.resolve())
    except (ValueError, OSError):
        return False


def render_file_content(file_path: Path) -> None:
    """
    Hi·ªÉn th·ªã n·ªôi dung file theo ƒë·ªãnh d·∫°ng: txt, json, jsonl, npy, pdf, csv.
    Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc ƒë·ªÉ tr√°nh treo.
    """
    if not file_path.is_file():
        st.warning("File kh√¥ng t·ªìn t·∫°i ho·∫∑c kh√¥ng ƒë·ªçc ƒë∆∞·ª£c.")
        return

    try:
        size = file_path.stat().st_size
    except OSError:
        st.error("Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c th√¥ng tin file.")
        return

    suffix = file_path.suffix.lower()

    # ---------- TXT ----------
    if suffix == ".txt":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File qu√° l·ªõn ({size / (1024*1024):.1f} MB). Ch·ªâ h·ªó tr·ª£ xem file ‚â§ {MAX_VIEW_TEXT_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            text = file_path.read_text(encoding="utf-8", errors="replace")
            st.code(text, language="text")
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc file: {e}")

    # ---------- JSON ----------
    elif suffix == ".json":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File qu√° l·ªõn. Ch·ªâ h·ªó tr·ª£ xem file ‚â§ {MAX_VIEW_TEXT_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            with file_path.open("r", encoding="utf-8") as f:
                data = json.load(f)
            st.json(data)
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc JSON: {e}")

    # ---------- JSONL ----------
    elif suffix == ".jsonl":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File qu√° l·ªõn. Ch·ªâ hi·ªÉn th·ªã t·ªëi ƒëa {MAX_JSONL_LINES} d√≤ng ƒë·∫ßu.")
        try:
            lines = []
            with file_path.open("r", encoding="utf-8", errors="replace") as f:
                for i, line in enumerate(f):
                    if i >= MAX_JSONL_LINES:
                        st.caption(f"‚Ä¶ Ch·ªâ hi·ªÉn th·ªã {MAX_JSONL_LINES} d√≤ng ƒë·∫ßu. T·ªïng file c√≥ th·ªÉ nhi·ªÅu h∆°n.")
                        break
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        lines.append(json.loads(line))
                    except json.JSONDecodeError:
                        lines.append({"raw": line})
            if lines:
                st.dataframe(lines, use_container_width=True)
            else:
                st.info("File r·ªóng ho·∫∑c kh√¥ng c√≥ d√≤ng JSON h·ª£p l·ªá.")
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc file: {e}")

    # ---------- NPY ----------
    elif suffix == ".npy":
        if size > MAX_VIEW_NPY_BYTES:
            st.warning(f"File qu√° l·ªõn ({size / (1024*1024):.1f} MB). Ch·ªâ h·ªó tr·ª£ xem file ‚â§ {MAX_VIEW_NPY_BYTES // (1024*1024)} MB.")
            _download_button(file_path)
            return
        try:
            import numpy as np
            arr = np.load(file_path, allow_pickle=False)
            st.write("**Shape:**", arr.shape)
            st.write("**Dtype:**", str(arr.dtype))
            if arr.size <= 100:
                st.write("**D·ªØ li·ªáu:**")
                st.write(arr)
            else:
                st.write("**M·∫´u (100 ph·∫ßn t·ª≠ ƒë·∫ßu):**")
                st.write(arr.flat[:100])
        except ImportError:
            st.info("C·∫ßn c√†i `numpy` ƒë·ªÉ xem file .npy. B·∫°n c√≥ th·ªÉ t·∫£i file xu·ªëng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc file .npy: {e}")

    # ---------- PDF ----------
    elif suffix == ".pdf":
        if size > MAX_VIEW_PDF_BYTES:
            st.warning(f"File qu√° l·ªõn. Ch·ªâ h·ªó tr·ª£ th√¥ng tin file ‚â§ {MAX_VIEW_PDF_BYTES // (1024*1024)} MB.")
        try:
            from pypdf import PdfReader
            reader = PdfReader(file_path)
            n_pages = len(reader.pages)
            st.write(f"**S·ªë trang:** {n_pages}")
            _download_button(file_path)
        except ImportError:
            st.info("C·∫ßn c√†i `pypdf` ƒë·ªÉ xem th√¥ng tin PDF. B·∫°n c√≥ th·ªÉ t·∫£i file xu·ªëng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc PDF: {e}")
            _download_button(file_path)

    # ---------- CSV ----------
    elif suffix == ".csv":
        if size > MAX_VIEW_TEXT_BYTES:
            st.warning(f"File qu√° l·ªõn. Ch·ªâ hi·ªÉn th·ªã m·ªôt ph·∫ßn.")
        try:
            import pandas as pd
            df = pd.read_csv(file_path, nrows=1000, encoding="utf-8", on_bad_lines="skip")
            st.dataframe(df, use_container_width=True)
            if size > 1024 * 1024:
                st.caption("Ch·ªâ hi·ªÉn th·ªã 1000 d√≤ng ƒë·∫ßu.")
        except ImportError:
            st.info("C·∫ßn c√†i `pandas` ƒë·ªÉ xem CSV. B·∫°n c√≥ th·ªÉ t·∫£i file xu·ªëng.")
            _download_button(file_path)
        except Exception as e:
            st.error(f"L·ªói ƒë·ªçc CSV: {e}")

    # ---------- Kh√°c ----------
    else:
        st.info(f"ƒê·ªãnh d·∫°ng `{suffix}` ch∆∞a h·ªó tr·ª£ xem tr·ª±c ti·∫øp. B·∫°n c√≥ th·ªÉ t·∫£i file xu·ªëng.")
        _download_button(file_path)


def _download_button(file_path: Path) -> None:
    try:
        data = file_path.read_bytes()
        st.download_button(
            "‚¨áÔ∏è T·∫£i file xu·ªëng",
            data=data,
            file_name=file_path.name,
            mime="application/octet-stream",
            key=f"dl_{hashlib.md5(str(file_path).encode()).hexdigest()[:16]}",
        )
    except Exception:
        pass


def render_sqlite_viewer(zone_path: Path) -> None:
    """
    SQLite viewer (ch·ªâ cho 500_catalog).
    """
    sqlite_files = [
        p for p in zone_path.iterdir()
        if p.is_file() and p.suffix in {".sqlite", ".db"}
    ]

    if not sqlite_files:
        st.info("Kh√¥ng t√¨m th·∫•y SQLite database trong 500_catalog")
        return

    st.divider()
    st.subheader("üìä SQLite Database Viewer")
    st.caption("Ch·∫ø ƒë·ªô ch·ªâ ƒë·ªçc ‚Äì ph·ª•c v·ª• ki·ªÉm tra catalog & ingest log")

    db_file = st.selectbox(
        "üóÑÔ∏è Ch·ªçn database",
        sqlite_files,
        format_func=lambda p: p.name,
    )

    try:
        conn = connect_readonly(db_file)
    except Exception as exc:
        st.error(f"Kh√¥ng m·ªü ƒë∆∞·ª£c database: {exc}")
        return

    try:
        tables = list_tables(conn)
    except Exception as exc:
        st.error(f"L·ªói ƒë·ªçc metadata database: {exc}")
        return

    if not tables:
        st.warning("Database kh√¥ng c√≥ b·∫£ng n√†o")
        return

    table = st.selectbox("üìã Ch·ªçn b·∫£ng", tables)

    # ---------- Schema ----------
    st.markdown("### üß± Schema")
    schema_df = get_table_schema(conn, table)
    st.dataframe(schema_df, use_container_width=True)

    # ---------- Data preview ----------
    st.markdown("### üëÅÔ∏è Preview d·ªØ li·ªáu")

    limit = st.slider(
        "S·ªë d√≤ng hi·ªÉn th·ªã",
        min_value=10,
        max_value=500,
        value=100,
        step=10,
    )

    try:
        data_df = preview_table(conn, table, limit)
        st.dataframe(data_df, use_container_width=True)
    except Exception as exc:
        st.error(f"L·ªói ƒë·ªçc d·ªØ li·ªáu b·∫£ng: {exc}")


# =====================================================
# MAIN PAGE
# =====================================================

def render():
    if not require_login():
        return

    st.header("üóÇÔ∏è Data Lake Explorer")

    # --------------------------------------------------
    # SELECT ZONE
    # --------------------------------------------------
    zone_name = st.selectbox(
        "üìÇ Ch·ªçn data zone",
        list(ZONES.keys()),
    )

    zone_path = ZONES[zone_name]

    if not zone_path.exists():
        st.warning(f"Zone ch∆∞a t·ªìn t·∫°i: {zone_path}")
        return

    st.subheader(f"üìÅ {zone_name}")

    # --------------------------------------------------
    # TREE VIEW ‚Äî LAZY: ch·ªâ load root khi v√†o; b·∫•m ‚ñ∂ m·ªõi load th∆∞ m·ª•c con
    # --------------------------------------------------
    if "datalake_expanded" not in st.session_state:
        st.session_state.datalake_expanded = {}
    expanded_set = st.session_state.datalake_expanded.setdefault(zone_name, set())

    with st.spinner("ƒêang t·∫£i..."):
        render_lazy_tree(zone_path, zone_name, expanded_set)

    # --------------------------------------------------
    # FILE CONTENT VIEWER (khi b·∫•m v√†o 1 file trong c√¢y)
    # --------------------------------------------------
    selected = st.session_state.get("datalake_selected_file")
    if selected:
        sel_path = Path(selected)
        if sel_path.is_file() and _is_safe_path(sel_path, zone_path):
            st.divider()
            st.subheader(f"üìÑ N·ªôi dung file: `{sel_path.name}`")
            if st.button("‚úï ƒê√≥ng xem file", key="datalake_close_file"):
                del st.session_state["datalake_selected_file"]
                st.rerun()
            render_file_content(sel_path)
        else:
            # File kh√¥ng c√≤n t·ªìn t·∫°i ho·∫∑c kh√¥ng thu·ªôc zone ‚Üí x√≥a l·ª±a ch·ªçn
            if "datalake_selected_file" in st.session_state:
                del st.session_state["datalake_selected_file"]

    # --------------------------------------------------
    # SQLITE VIEWER (ONLY 500_catalog)
    # --------------------------------------------------
    if zone_name == "500_catalog":
        render_sqlite_viewer(zone_path)
